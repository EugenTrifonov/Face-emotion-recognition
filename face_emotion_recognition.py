# -*- coding: utf-8 -*-
"""Face_emotion_recognition.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SaUN9lTDF4Lx7qR7leyktegv6sTjI4uL
"""

!pip install opendatasets --upgrade --quiet
!pip install tensorflow-gpu
!pip install tensorflow

import opendatasets as od
dataset_url = 'https://www.kaggle.com/msambare/fer2013'
od.download(dataset_url)

import tensorflow as tf
import cv2
import os
import matplotlib.pyplot as plt
import numpy as np
from tensorflow import  keras
from tensorflow.keras import layers
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.preprocessing import image_dataset_from_directory
from tensorflow.python.keras.callbacks import LearningRateScheduler
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, Flatten, Input
from tensorflow.keras.layers import Conv2D,BatchNormalization
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.layers import MaxPooling2D
from tensorflow.keras.preprocessing import image
from keras.optimizers import Adam, RMSprop, SGD
from keras import regularizers
from keras.callbacks import ModelCheckpoint, CSVLogger, TensorBoard, EarlyStopping, ReduceLROnPlateau

!rm -r "/content/fer2013/test/disgust"
!rm -r "/content/fer2013/train/disgust"

folders=os.listdir('/content/fer2013/train/')
for i in folders:
  img_folder_path = '/content/fer2013/train/'+ i
  dirListing = os.listdir(img_folder_path)
  print(i)
  print(len(dirListing))

train_dir = "/content/fer2013/train"
val_dir = "/content/fer2013/test"
log_dir="/content/logs"
BATCH_SIZE = 64
IMG_SIZE=48
NUM_CLASSES=6

train_image_generator= ImageDataGenerator(rescale=1./255,
                                         zoom_range=0.3,
                                         horizontal_flip=True 
                                          )

train_generator = train_image_generator.flow_from_directory(
        train_dir,
        target_size=(48,48),
        batch_size=BATCH_SIZE,
        color_mode="grayscale",
        class_mode='categorical',
        shuffle=True
        )

validation_generator = train_image_generator.flow_from_directory(
        val_dir,
        target_size=(48,48),
        batch_size=BATCH_SIZE,
        color_mode="grayscale",
        class_mode='categorical',
        shuffle=True
        )

print(train_generator.class_indices)
print(validation_generator.class_indices)

model = tf.keras.models.Sequential()   

model.add(Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu', input_shape =(48,48,1)))
model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'))
model.add(BatchNormalization())
model.add(MaxPooling2D(2, 2))
model.add(Dropout(0.25))

model.add(Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.01)))
model.add(Conv2D(256, kernel_size=(3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.01)))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))

model.add(Flatten())
model.add(Dense(1024, activation='relu'))
model.add(Dropout(0.5))
    
model.add(Dense(6, activation='softmax'))

reduce_lr = ReduceLROnPlateau(monitor='val_loss', 
                              factor=0.2, 
                              patience=6, 
                              verbose=1, 
                              min_delta=0.0001)

steps_per_epoch = train_generator.n // train_generator.batch_size
validation_steps = validation_generator.n // validation_generator.batch_size

model.compile(loss='categorical_crossentropy',optimizer=Adam(lr=0.0001, decay=1e-6),metrics=['accuracy'])

model.summary()

model.fit(train_generator,
          epochs=55,
          steps_per_epoch=steps_per_epoch,
          validation_data=validation_generator,
          validation_steps=validation_steps,
          callbacks=[
            tf.keras.callbacks.TensorBoard(log_dir),reduce_lr
                  ]
          )

model.save_weights('model.h5')

from google.colab import files
files.download(model.h5)

def emotion_graph(emotions):
    objects = ('angry', 'fear', 'happy', 'neutral',    'sad', 'surprise')
    y_pos = np.arange(len(objects))
    plt.bar(y_pos, emotions, align='center', alpha=0.5)
    plt.xticks(y_pos, objects)
    plt.ylabel('percentage Value')
    plt.title('Emotion Graph')
    plt.show()

faceCascade=cv2.CascadeClassifier(cv2.data.haarcascades+'haarcascade_frontalface_default.xml')

frame = cv2.imread('/content/test_14.jpg')
frame=cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)
gray=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)

plt.imshow(frame)

faces=faceCascade.detectMultiScale(gray,1.1,4)
for x,y,w,h in faces:
  roi_gray=gray[y:y+h, x:x+w]
  roi_color=frame[y:y+h, x:x+w] 
  cv2.rectangle(frame,(x,y),(x+w, y+h),(255,0,0),2)
  facess=faceCascade.detectMultiScale(roi_gray)
  if len(faces)== 0:
    print("Face not detected")
  else:
      for (ex,ey,ew,eh) in facess:
        face_roi=roi_color[ey: ey+eh, ex:ex + ew]

plt.imshow(frame)

plt.imshow(face_roi,cmap='gray')
face_roi.shape

"""Grayscale"""

face_roi=cv2.resize(face_roi,(48,48))
face_roi=cv2.cvtColor(face_roi,cv2.COLOR_RGB2GRAY)
dim_1=image.img_to_array(face_roi)
dim_1 = np.expand_dims(dim_1, 2)
dim_2=np.expand_dims(dim_1,0)

"""RGB"""

face_roi_resize=cv2.resize(face_roi,(48,48))
dim_1=image.img_to_array(face_roi_resize)
dim_2=np.expand_dims(dim_1,0)

custom = model.predict(dim_2)
emotion_graph(custom[0])

img_test = image.load_img("/content/test_4.png", color_mode = "grayscale",    target_size=(48,48))
x = image.img_to_array(img_test)
print(x.shape)
x = np.expand_dims(x, axis = 0)
x /= 255
print(x.shape)
custom = model.predict(x)
emotion_graph(custom[0])

# Commented out IPython magic to ensure Python compatibility.
# %load_ext tensorboard

# Commented out IPython magic to ensure Python compatibility.
# %reload_ext tensorboard
# %tensorboard --logdir logs/